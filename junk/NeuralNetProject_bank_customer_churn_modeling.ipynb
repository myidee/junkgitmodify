{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: Given a Bank customer, can we build a classifier which can determine whether they will leave or not using Neural networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic Python packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data_df = pd.read_csv('bank.csv')\n",
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Drop the columns which are unique for all users like IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data_df = bank_data_df.drop(['RowNumber','CustomerId','Surname'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "0          1               1        101348.88       1  \n",
       "1          0               1        112542.58       0  \n",
       "2          1               0        113931.57       1  \n",
       "3          0               0         93826.63       0  \n",
       "4          1               1         79084.10       0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Distinguish the feature and target set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining y as the feature that indicates if the customer has exited or not\n",
    "y = bank_data_df['Exited']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining X as the rest of the features\n",
    "X = bank_data_df.drop(['Exited'],axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0             619    France  Female   42       2       0.00              1   \n",
      "1             608     Spain  Female   41       1   83807.86              1   \n",
      "2             502    France  Female   42       8  159660.80              3   \n",
      "3             699    France  Female   39       1       0.00              2   \n",
      "4             850     Spain  Female   43       2  125510.82              1   \n",
      "5             645     Spain    Male   44       8  113755.78              2   \n",
      "6             822    France    Male   50       7       0.00              2   \n",
      "7             376   Germany  Female   29       4  115046.74              4   \n",
      "8             501    France    Male   44       4  142051.07              2   \n",
      "9             684    France    Male   27       2  134603.88              1   \n",
      "10            528    France    Male   31       6  102016.72              2   \n",
      "11            497     Spain    Male   24       3       0.00              2   \n",
      "12            476    France  Female   34      10       0.00              2   \n",
      "13            549    France  Female   25       5       0.00              2   \n",
      "14            635     Spain  Female   35       7       0.00              2   \n",
      "15            616   Germany    Male   45       3  143129.41              2   \n",
      "16            653   Germany    Male   58       1  132602.88              1   \n",
      "17            549     Spain  Female   24       9       0.00              2   \n",
      "18            587     Spain    Male   45       6       0.00              1   \n",
      "19            726    France  Female   24       6       0.00              2   \n",
      "20            732    France    Male   41       8       0.00              2   \n",
      "21            636     Spain  Female   32       8       0.00              2   \n",
      "22            510     Spain  Female   38       4       0.00              1   \n",
      "23            669    France    Male   46       3       0.00              2   \n",
      "24            846    France  Female   38       5       0.00              1   \n",
      "25            577    France    Male   25       3       0.00              2   \n",
      "26            756   Germany    Male   36       2  136815.64              1   \n",
      "27            571    France    Male   44       9       0.00              2   \n",
      "28            574   Germany  Female   43       3  141349.43              1   \n",
      "29            411    France    Male   29       0   59697.17              2   \n",
      "...           ...       ...     ...  ...     ...        ...            ...   \n",
      "9970          518    France    Male   42       7  151027.05              2   \n",
      "9971          833    France  Female   34       3  144751.81              1   \n",
      "9972          758    France    Male   26       4  155739.76              1   \n",
      "9973          611    France    Male   27       7       0.00              2   \n",
      "9974          583    France    Male   33       7  122531.86              1   \n",
      "9975          610   Germany    Male   50       1  113957.01              2   \n",
      "9976          637    France  Female   33       7  103377.81              1   \n",
      "9977          683    France  Female   32       9       0.00              2   \n",
      "9978          774    France    Male   40       9   93017.47              2   \n",
      "9979          677    France  Female   58       1   90022.85              1   \n",
      "9980          741     Spain    Male   35       6   74371.49              1   \n",
      "9981          498   Germany    Male   42       3  152039.70              1   \n",
      "9982          655   Germany  Female   46       7  137145.12              1   \n",
      "9983          613    France    Male   40       4       0.00              1   \n",
      "9984          602   Germany    Male   35       7   90602.42              2   \n",
      "9985          659    France    Male   36       6  123841.49              2   \n",
      "9986          673   Germany    Male   47       1  183579.54              2   \n",
      "9987          606     Spain    Male   30       8  180307.73              2   \n",
      "9988          775    France    Male   30       4       0.00              2   \n",
      "9989          841     Spain    Male   28       4       0.00              2   \n",
      "9990          714   Germany    Male   33       3   35016.60              1   \n",
      "9991          597    France  Female   53       4   88381.21              1   \n",
      "9992          726     Spain    Male   36       2       0.00              1   \n",
      "9993          644    France    Male   28       7  155060.41              1   \n",
      "9994          800    France  Female   29       2       0.00              2   \n",
      "9995          771    France    Male   39       5       0.00              2   \n",
      "9996          516    France    Male   35      10   57369.61              1   \n",
      "9997          709    France  Female   36       7       0.00              1   \n",
      "9998          772   Germany    Male   42       3   75075.31              2   \n",
      "9999          792    France  Female   28       4  130142.79              1   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0             1               1        101348.88  \n",
      "1             0               1        112542.58  \n",
      "2             1               0        113931.57  \n",
      "3             0               0         93826.63  \n",
      "4             1               1         79084.10  \n",
      "5             1               0        149756.71  \n",
      "6             1               1         10062.80  \n",
      "7             1               0        119346.88  \n",
      "8             0               1         74940.50  \n",
      "9             1               1         71725.73  \n",
      "10            0               0         80181.12  \n",
      "11            1               0         76390.01  \n",
      "12            1               0         26260.98  \n",
      "13            0               0        190857.79  \n",
      "14            1               1         65951.65  \n",
      "15            0               1         64327.26  \n",
      "16            1               0          5097.67  \n",
      "17            1               1         14406.41  \n",
      "18            0               0        158684.81  \n",
      "19            1               1         54724.03  \n",
      "20            1               1        170886.17  \n",
      "21            1               0        138555.46  \n",
      "22            1               0        118913.53  \n",
      "23            0               1          8487.75  \n",
      "24            1               1        187616.16  \n",
      "25            0               1        124508.29  \n",
      "26            1               1        170041.95  \n",
      "27            0               0         38433.35  \n",
      "28            1               1        100187.43  \n",
      "29            1               1         53483.21  \n",
      "...         ...             ...              ...  \n",
      "9970          1               0        119377.36  \n",
      "9971          0               0        166472.81  \n",
      "9972          1               0        171552.02  \n",
      "9973          1               1        157474.10  \n",
      "9974          1               0         13549.24  \n",
      "9975          1               0        196526.55  \n",
      "9976          1               0         84419.78  \n",
      "9977          1               1         24991.92  \n",
      "9978          1               0        191608.97  \n",
      "9979          0               1          2988.28  \n",
      "9980          0               0         99595.67  \n",
      "9981          1               1         53445.17  \n",
      "9982          1               0        115146.40  \n",
      "9983          0               0        151325.24  \n",
      "9984          1               1         51695.41  \n",
      "9985          1               0         96833.00  \n",
      "9986          0               1         34047.54  \n",
      "9987          1               1          1914.41  \n",
      "9988          1               0         49337.84  \n",
      "9989          1               1        179436.60  \n",
      "9990          1               0         53667.08  \n",
      "9991          1               0         69384.71  \n",
      "9992          1               0        195192.40  \n",
      "9993          1               0         29179.52  \n",
      "9994          0               0        167773.55  \n",
      "9995          1               0         96270.64  \n",
      "9996          1               1        101699.77  \n",
      "9997          0               1         42085.58  \n",
      "9998          1               0         92888.52  \n",
      "9999          1               0         38190.78  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "# First encoding Geography\n",
    "labelEnc_1 = LabelEncoder()\n",
    "X['Geography'] = labelEnc_1.fit_transform(X['Geography'])\n",
    "\n",
    "# Now encoding Gender\n",
    "labelEnc_2 = LabelEncoder()\n",
    "X['Gender'] = labelEnc_2.fit_transform(X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore  Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
      "0             619          0       0   42       2       0.00              1   \n",
      "1             608          2       0   41       1   83807.86              1   \n",
      "2             502          0       0   42       8  159660.80              3   \n",
      "3             699          0       0   39       1       0.00              2   \n",
      "4             850          2       0   43       2  125510.82              1   \n",
      "5             645          2       1   44       8  113755.78              2   \n",
      "6             822          0       1   50       7       0.00              2   \n",
      "7             376          1       0   29       4  115046.74              4   \n",
      "8             501          0       1   44       4  142051.07              2   \n",
      "9             684          0       1   27       2  134603.88              1   \n",
      "10            528          0       1   31       6  102016.72              2   \n",
      "11            497          2       1   24       3       0.00              2   \n",
      "12            476          0       0   34      10       0.00              2   \n",
      "13            549          0       0   25       5       0.00              2   \n",
      "14            635          2       0   35       7       0.00              2   \n",
      "15            616          1       1   45       3  143129.41              2   \n",
      "16            653          1       1   58       1  132602.88              1   \n",
      "17            549          2       0   24       9       0.00              2   \n",
      "18            587          2       1   45       6       0.00              1   \n",
      "19            726          0       0   24       6       0.00              2   \n",
      "20            732          0       1   41       8       0.00              2   \n",
      "21            636          2       0   32       8       0.00              2   \n",
      "22            510          2       0   38       4       0.00              1   \n",
      "23            669          0       1   46       3       0.00              2   \n",
      "24            846          0       0   38       5       0.00              1   \n",
      "25            577          0       1   25       3       0.00              2   \n",
      "26            756          1       1   36       2  136815.64              1   \n",
      "27            571          0       1   44       9       0.00              2   \n",
      "28            574          1       0   43       3  141349.43              1   \n",
      "29            411          0       1   29       0   59697.17              2   \n",
      "...           ...        ...     ...  ...     ...        ...            ...   \n",
      "9970          518          0       1   42       7  151027.05              2   \n",
      "9971          833          0       0   34       3  144751.81              1   \n",
      "9972          758          0       1   26       4  155739.76              1   \n",
      "9973          611          0       1   27       7       0.00              2   \n",
      "9974          583          0       1   33       7  122531.86              1   \n",
      "9975          610          1       1   50       1  113957.01              2   \n",
      "9976          637          0       0   33       7  103377.81              1   \n",
      "9977          683          0       0   32       9       0.00              2   \n",
      "9978          774          0       1   40       9   93017.47              2   \n",
      "9979          677          0       0   58       1   90022.85              1   \n",
      "9980          741          2       1   35       6   74371.49              1   \n",
      "9981          498          1       1   42       3  152039.70              1   \n",
      "9982          655          1       0   46       7  137145.12              1   \n",
      "9983          613          0       1   40       4       0.00              1   \n",
      "9984          602          1       1   35       7   90602.42              2   \n",
      "9985          659          0       1   36       6  123841.49              2   \n",
      "9986          673          1       1   47       1  183579.54              2   \n",
      "9987          606          2       1   30       8  180307.73              2   \n",
      "9988          775          0       1   30       4       0.00              2   \n",
      "9989          841          2       1   28       4       0.00              2   \n",
      "9990          714          1       1   33       3   35016.60              1   \n",
      "9991          597          0       0   53       4   88381.21              1   \n",
      "9992          726          2       1   36       2       0.00              1   \n",
      "9993          644          0       1   28       7  155060.41              1   \n",
      "9994          800          0       0   29       2       0.00              2   \n",
      "9995          771          0       1   39       5       0.00              2   \n",
      "9996          516          0       1   35      10   57369.61              1   \n",
      "9997          709          0       0   36       7       0.00              1   \n",
      "9998          772          1       1   42       3   75075.31              2   \n",
      "9999          792          0       0   28       4  130142.79              1   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
      "0             1               1        101348.88  \n",
      "1             0               1        112542.58  \n",
      "2             1               0        113931.57  \n",
      "3             0               0         93826.63  \n",
      "4             1               1         79084.10  \n",
      "5             1               0        149756.71  \n",
      "6             1               1         10062.80  \n",
      "7             1               0        119346.88  \n",
      "8             0               1         74940.50  \n",
      "9             1               1         71725.73  \n",
      "10            0               0         80181.12  \n",
      "11            1               0         76390.01  \n",
      "12            1               0         26260.98  \n",
      "13            0               0        190857.79  \n",
      "14            1               1         65951.65  \n",
      "15            0               1         64327.26  \n",
      "16            1               0          5097.67  \n",
      "17            1               1         14406.41  \n",
      "18            0               0        158684.81  \n",
      "19            1               1         54724.03  \n",
      "20            1               1        170886.17  \n",
      "21            1               0        138555.46  \n",
      "22            1               0        118913.53  \n",
      "23            0               1          8487.75  \n",
      "24            1               1        187616.16  \n",
      "25            0               1        124508.29  \n",
      "26            1               1        170041.95  \n",
      "27            0               0         38433.35  \n",
      "28            1               1        100187.43  \n",
      "29            1               1         53483.21  \n",
      "...         ...             ...              ...  \n",
      "9970          1               0        119377.36  \n",
      "9971          0               0        166472.81  \n",
      "9972          1               0        171552.02  \n",
      "9973          1               1        157474.10  \n",
      "9974          1               0         13549.24  \n",
      "9975          1               0        196526.55  \n",
      "9976          1               0         84419.78  \n",
      "9977          1               1         24991.92  \n",
      "9978          1               0        191608.97  \n",
      "9979          0               1          2988.28  \n",
      "9980          0               0         99595.67  \n",
      "9981          1               1         53445.17  \n",
      "9982          1               0        115146.40  \n",
      "9983          0               0        151325.24  \n",
      "9984          1               1         51695.41  \n",
      "9985          1               0         96833.00  \n",
      "9986          0               1         34047.54  \n",
      "9987          1               1          1914.41  \n",
      "9988          1               0         49337.84  \n",
      "9989          1               1        179436.60  \n",
      "9990          1               0         53667.08  \n",
      "9991          1               0         69384.71  \n",
      "9992          1               0        195192.40  \n",
      "9993          1               0         29179.52  \n",
      "9994          0               0        167773.55  \n",
      "9995          1               0         96270.64  \n",
      "9996          1               1        101699.77  \n",
      "9997          0               1         42085.58  \n",
      "9998          1               0         92888.52  \n",
      "9999          1               0         38190.78  \n",
      "\n",
      "[10000 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0000000e+00 0.0000000e+00 6.1900000e+02 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0134888e+05]\n",
      " [0.0000000e+00 1.0000000e+00 6.0800000e+02 ... 0.0000000e+00\n",
      "  1.0000000e+00 1.1254258e+05]\n",
      " [0.0000000e+00 0.0000000e+00 5.0200000e+02 ... 1.0000000e+00\n",
      "  0.0000000e+00 1.1393157e+05]\n",
      " ...\n",
      " [0.0000000e+00 0.0000000e+00 7.0900000e+02 ... 0.0000000e+00\n",
      "  1.0000000e+00 4.2085580e+04]\n",
      " [1.0000000e+00 0.0000000e+00 7.7200000e+02 ... 1.0000000e+00\n",
      "  0.0000000e+00 9.2888520e+04]\n",
      " [0.0000000e+00 0.0000000e+00 7.9200000e+02 ... 1.0000000e+00\n",
      "  0.0000000e+00 3.8190780e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Divide the data set into Train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Normalize the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdScaler = StandardScaler()\n",
    "X_train = stdScaler.fit_transform(X_train)\n",
    "X_test = stdScaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Initialize & build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "model.add(tf.keras.layers.Dense(6,input_dim=11,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "model.add(tf.keras.layers.Dense(6,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output layer\n",
    "model.add(tf.keras.layers.Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Optimize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimizer with non-default learning rate\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=sgd_optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "7000/7000 [==============================] - 2s 262us/sample - loss: 0.4825 - acc: 0.7940\n",
      "Epoch 2/100\n",
      "7000/7000 [==============================] - 2s 240us/sample - loss: 0.4355 - acc: 0.7986\n",
      "Epoch 3/100\n",
      "7000/7000 [==============================] - 2s 269us/sample - loss: 0.4230 - acc: 0.8050\n",
      "Epoch 4/100\n",
      "7000/7000 [==============================] - 2s 303us/sample - loss: 0.4144 - acc: 0.8167\n",
      "Epoch 5/100\n",
      "7000/7000 [==============================] - 2s 254us/sample - loss: 0.4032 - acc: 0.8274\n",
      "Epoch 6/100\n",
      "7000/7000 [==============================] - 2s 244us/sample - loss: 0.3838 - acc: 0.8383\n",
      "Epoch 7/100\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 0.3623 - acc: 0.8514\n",
      "Epoch 8/100\n",
      "7000/7000 [==============================] - 1s 179us/sample - loss: 0.3535 - acc: 0.8544\n",
      "Epoch 9/100\n",
      "7000/7000 [==============================] - 2s 251us/sample - loss: 0.3507 - acc: 0.8534\n",
      "Epoch 10/100\n",
      "7000/7000 [==============================] - 2s 220us/sample - loss: 0.3503 - acc: 0.8553\n",
      "Epoch 11/100\n",
      "7000/7000 [==============================] - 1s 161us/sample - loss: 0.3468 - acc: 0.8546\n",
      "Epoch 12/100\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.3468 - acc: 0.8534\n",
      "Epoch 13/100\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.3445 - acc: 0.8550\n",
      "Epoch 14/100\n",
      "7000/7000 [==============================] - 1s 179us/sample - loss: 0.3439 - acc: 0.8566\n",
      "Epoch 15/100\n",
      "7000/7000 [==============================] - ETA: 0s - loss: 0.3445 - acc: 0.853 - 1s 213us/sample - loss: 0.3432 - acc: 0.8544\n",
      "Epoch 16/100\n",
      "7000/7000 [==============================] - 2s 222us/sample - loss: 0.3425 - acc: 0.8604\n",
      "Epoch 17/100\n",
      "7000/7000 [==============================] - 2s 238us/sample - loss: 0.3421 - acc: 0.8587\n",
      "Epoch 18/100\n",
      "7000/7000 [==============================] - 1s 180us/sample - loss: 0.3403 - acc: 0.8609\n",
      "Epoch 19/100\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.3394 - acc: 0.8597\n",
      "Epoch 20/100\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 0.3397 - acc: 0.8617\n",
      "Epoch 21/100\n",
      "7000/7000 [==============================] - 1s 174us/sample - loss: 0.3390 - acc: 0.8597s - loss: 0.3363 - acc\n",
      "Epoch 22/100\n",
      "7000/7000 [==============================] - 1s 182us/sample - loss: 0.3391 - acc: 0.8616\n",
      "Epoch 23/100\n",
      "7000/7000 [==============================] - 1s 186us/sample - loss: 0.3388 - acc: 0.8617\n",
      "Epoch 24/100\n",
      "7000/7000 [==============================] - 1s 208us/sample - loss: 0.3374 - acc: 0.8594\n",
      "Epoch 25/100\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.3382 - acc: 0.8597\n",
      "Epoch 26/100\n",
      "7000/7000 [==============================] - 1s 192us/sample - loss: 0.3373 - acc: 0.8583\n",
      "Epoch 27/100\n",
      "7000/7000 [==============================] - 1s 179us/sample - loss: 0.3369 - acc: 0.8621\n",
      "Epoch 28/100\n",
      "7000/7000 [==============================] - 1s 175us/sample - loss: 0.3359 - acc: 0.8619\n",
      "Epoch 29/100\n",
      "7000/7000 [==============================] - 1s 164us/sample - loss: 0.3357 - acc: 0.8631\n",
      "Epoch 30/100\n",
      "7000/7000 [==============================] - 1s 168us/sample - loss: 0.3358 - acc: 0.8626\n",
      "Epoch 31/100\n",
      "7000/7000 [==============================] - 1s 167us/sample - loss: 0.3349 - acc: 0.8614\n",
      "Epoch 32/100\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.3355 - acc: 0.8634\n",
      "Epoch 33/100\n",
      "7000/7000 [==============================] - 1s 197us/sample - loss: 0.3354 - acc: 0.8613\n",
      "Epoch 34/100\n",
      "7000/7000 [==============================] - 1s 186us/sample - loss: 0.3350 - acc: 0.8639\n",
      "Epoch 35/100\n",
      "7000/7000 [==============================] - 2s 235us/sample - loss: 0.3344 - acc: 0.8647\n",
      "Epoch 36/100\n",
      "7000/7000 [==============================] - 1s 155us/sample - loss: 0.3345 - acc: 0.8619\n",
      "Epoch 37/100\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 0.3341 - acc: 0.8607\n",
      "Epoch 38/100\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.3347 - acc: 0.8636\n",
      "Epoch 39/100\n",
      "7000/7000 [==============================] - 1s 156us/sample - loss: 0.3337 - acc: 0.8646\n",
      "Epoch 40/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3336 - acc: 0.8641\n",
      "Epoch 41/100\n",
      "7000/7000 [==============================] - 1s 158us/sample - loss: 0.3324 - acc: 0.8639\n",
      "Epoch 42/100\n",
      "7000/7000 [==============================] - 1s 153us/sample - loss: 0.3330 - acc: 0.8634\n",
      "Epoch 43/100\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3328 - acc: 0.8637\n",
      "Epoch 44/100\n",
      "7000/7000 [==============================] - 1s 153us/sample - loss: 0.3317 - acc: 0.8627\n",
      "Epoch 45/100\n",
      "7000/7000 [==============================] - 1s 155us/sample - loss: 0.3327 - acc: 0.8646\n",
      "Epoch 46/100\n",
      "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3317 - acc: 0.8643\n",
      "Epoch 47/100\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3329 - acc: 0.8627\n",
      "Epoch 48/100\n",
      "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3326 - acc: 0.8619\n",
      "Epoch 49/100\n",
      "7000/7000 [==============================] - 1s 150us/sample - loss: 0.3327 - acc: 0.8637\n",
      "Epoch 50/100\n",
      "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3316 - acc: 0.8637\n",
      "Epoch 51/100\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3317 - acc: 0.8610\n",
      "Epoch 52/100\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3317 - acc: 0.8630\n",
      "Epoch 53/100\n",
      "7000/7000 [==============================] - 1s 166us/sample - loss: 0.3311 - acc: 0.8627\n",
      "Epoch 54/100\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3312 - acc: 0.8630\n",
      "Epoch 55/100\n",
      "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3313 - acc: 0.8617\n",
      "Epoch 56/100\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3302 - acc: 0.8639\n",
      "Epoch 57/100\n",
      "7000/7000 [==============================] - 1s 161us/sample - loss: 0.3312 - acc: 0.8631\n",
      "Epoch 58/100\n",
      "7000/7000 [==============================] - 1s 192us/sample - loss: 0.3299 - acc: 0.8623\n",
      "Epoch 59/100\n",
      "7000/7000 [==============================] - 1s 154us/sample - loss: 0.3301 - acc: 0.8621s - loss: 0.3334 - acc:\n",
      "Epoch 60/100\n",
      "7000/7000 [==============================] - 1s 153us/sample - loss: 0.3288 - acc: 0.8621\n",
      "Epoch 61/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3296 - acc: 0.8620\n",
      "Epoch 62/100\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3297 - acc: 0.8617\n",
      "Epoch 63/100\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3296 - acc: 0.8613\n",
      "Epoch 64/100\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3293 - acc: 0.8627\n",
      "Epoch 65/100\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3292 - acc: 0.8643\n",
      "Epoch 66/100\n",
      "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3288 - acc: 0.8626\n",
      "Epoch 67/100\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3285 - acc: 0.8637\n",
      "Epoch 68/100\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3296 - acc: 0.8631\n",
      "Epoch 69/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3290 - acc: 0.8631\n",
      "Epoch 70/100\n",
      "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3295 - acc: 0.8626\n",
      "Epoch 71/100\n",
      "7000/7000 [==============================] - 1s 148us/sample - loss: 0.3286 - acc: 0.8646\n",
      "Epoch 72/100\n",
      "7000/7000 [==============================] - 1s 158us/sample - loss: 0.3285 - acc: 0.8623\n",
      "Epoch 73/100\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3288 - acc: 0.8631\n",
      "Epoch 74/100\n",
      "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3284 - acc: 0.8611\n",
      "Epoch 75/100\n",
      "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3276 - acc: 0.8644\n",
      "Epoch 76/100\n",
      "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3285 - acc: 0.8631\n",
      "Epoch 77/100\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3274 - acc: 0.8634\n",
      "Epoch 78/100\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3286 - acc: 0.8626\n",
      "Epoch 79/100\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3291 - acc: 0.8633\n",
      "Epoch 80/100\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3278 - acc: 0.8647\n",
      "Epoch 81/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3279 - acc: 0.8650\n",
      "Epoch 82/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3275 - acc: 0.8623\n",
      "Epoch 83/100\n",
      "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3280 - acc: 0.8656\n",
      "Epoch 84/100\n",
      "7000/7000 [==============================] - 1s 149us/sample - loss: 0.3279 - acc: 0.8644\n",
      "Epoch 85/100\n",
      "7000/7000 [==============================] - 1s 158us/sample - loss: 0.3277 - acc: 0.8623\n",
      "Epoch 86/100\n",
      "7000/7000 [==============================] - 1s 172us/sample - loss: 0.3275 - acc: 0.8637s - loss: 0.3281 - acc: 0.863\n",
      "Epoch 87/100\n",
      "7000/7000 [==============================] - 1s 159us/sample - loss: 0.3279 - acc: 0.8617s - loss: 0.3293 - acc: 0. - ETA: 0s - loss: 0.3263 - acc: 0.\n",
      "Epoch 88/100\n",
      "7000/7000 [==============================] - 1s 155us/sample - loss: 0.3276 - acc: 0.8641\n",
      "Epoch 89/100\n",
      "7000/7000 [==============================] - 1s 161us/sample - loss: 0.3275 - acc: 0.8647\n",
      "Epoch 90/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3274 - acc: 0.8650\n",
      "Epoch 91/100\n",
      "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3276 - acc: 0.8649\n",
      "Epoch 92/100\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3270 - acc: 0.8644\n",
      "Epoch 93/100\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3285 - acc: 0.8633\n",
      "Epoch 94/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3276 - acc: 0.8654\n",
      "Epoch 95/100\n",
      "7000/7000 [==============================] - 1s 141us/sample - loss: 0.3271 - acc: 0.8639\n",
      "Epoch 96/100\n",
      "7000/7000 [==============================] - 1s 139us/sample - loss: 0.3271 - acc: 0.8627\n",
      "Epoch 97/100\n",
      "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3268 - acc: 0.8654\n",
      "Epoch 98/100\n",
      "7000/7000 [==============================] - 1s 147us/sample - loss: 0.3272 - acc: 0.8643\n",
      "Epoch 99/100\n",
      "7000/7000 [==============================] - 1s 143us/sample - loss: 0.3266 - acc: 0.8646\n",
      "Epoch 100/100\n",
      "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3266 - acc: 0.8656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a33208438>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, batch_size = 10, nb_epoch = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 8. Predict the results using 0.5 as a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ...\n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Print the Accuracy score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[2260  113]\n",
      " [ 301  326]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "ConfMatrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix: \\n{}\".format(ConfMatrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 86.20%\n"
     ]
    }
   ],
   "source": [
    "# Printing the accuracy\n",
    "print(\"Accuracy is {:.2f}%\".format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
